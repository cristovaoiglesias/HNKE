# using DifferentialEquations, DiffEqFlux, Plots, Statistics
# using XLSX, DataFrames, Optim, BlackBoxOptim,DiffEqParamEstim, CSV, Tables
# using Flux
# using BSON: @save
# using BSON#: @load
# using OrdinaryDiffEq, Optimization, OptimizationOptimJL, OptimizationOptimisers
# using Random, ComponentArrays, Lux

# using ComponentArrays, Lux, DiffEqFlux, OrdinaryDiffEq, Optimization, OptimizationOptimJL
# using OptimizationOptimisers, Random, Plots, DifferentialEquations

using Flux, DiffEqFlux, DifferentialEquations, Plots

function ode_system!(du, u, p, t)
    Xv, GLC, GLN, LAC, AMM, mAb = u
    μ_Xv, μ_GLC, μ_GLN, μ_LAC, μ_AMM, μ_mAb = p
    du[1] = μ_Xv*Xv  #dXv
    du[2] = -μ_GLC*Xv #dGLC
    du[3] = -μ_GLN*Xv #dGLN
    du[4] = μ_LAC*Xv #+ klac1*GLC + klac2*GLN   #dLAC
    du[5] = μ_AMM*Xv  #- klac1*GLC  #μ_AMM*Xv - kdeg*du[3] #dAMM #(eq10: dAMM)
    du[6] = μ_mAb*Xv
end
tstart=0.0
tend=103.0
sampling= 7.0
tgrid=tstart:sampling:tend
tgrid_opt=[0.0, 7.0, 14.0, 21.0, 28.0, 35.0, 42.0, 49.0, 56.0, 63.0, 70.0, 77.0, 84.0, 91.0, 98.0]


sol_SP2_trainingset2=[1.767106549104878e8 4.8034118791163415e8 28.79936374789464 8.67313487957298 2.942788370043843 0.39937762872941024 52.172325660037004; 1.581743111876225e8 3.4140584236600626e8 32.75525128794138 7.827187880277974 1.6851328540289636 0.6528574257375422 201.25619728296184; 3.780782920512088e8 5.359025455205498e8 29.35504815727434 8.710815405721698 6.842912252447374 1.6598951524771344 211.46247003201654; 5.101075371098536e8 3.7508090858754444e8 25.54793104220216 7.117035112115489 5.620397407940267 2.2684938286417715 170.355176208597; 7.85148993232183e8 8.17658357813659e8 21.68421210719685 6.0941422029583325 6.735256471998822 2.994092081099956 215.95934153698425; 6.191407593950603e8 8.461529496956238e8 21.93927189020505 5.705503661797384 10.26964865478049 3.8071332829211215 314.32509365079693; 9.139485475075808e8 1.0054332179856901e9 16.71796903965358 4.665749995434605 14.865848976492037 4.132248465169267 372.91690412697506; 1.0196122477857962e9 1.0434987266078699e9 15.780324595437056 3.534445664864008 18.51141036419648 2.617989288192452 489.86301637135585; 1.0440846693410515e9 1.4898040302274673e9 15.628553643875714 2.745896700760228 20.399953060266444 4.58333958883263 590.7464098386414; 1.2747674922238803e9 1.3131494852611752e9 13.350122992624048 2.0134463160828924 24.014752782883562 6.200683466923683 654.1606596731951; 1.3197162842362485e9 1.5663112225190232e9 7.107776134642888 2.199100640685581 30.44261473909391 5.6873155651330825 710.3742173117361; 1.3341943566904027e9 1.952269795040228e9 8.088768250313475 0.1586338112249217 35.76339722410659 5.657676638989609 890.1592175866458; 1.288125596141017e9 1.922231527420238e9 7.679720226681464 0.13440159577627697 33.701152200604504 5.690250919760564 1004.754457067872; 1.1649833330008502e9 1.881109552767151e9 1.8778783341683682 0.023909555859245486 38.37951703172009 5.349466508869145 1254.693440566674; 1.0045339970275251e9 1.7114099704657812e9 1.4579850090948518 0.6107891945584328 41.856932926405946 6.136380293621595 1359.6524108936587]'

trainingset=sol_SP2_trainingset2

full_path="/Users/cristovao/PhD_courses/Thesis/BHM_NSE_vs_EnMLP_NSE/estimating_parameters/SP2/estimation_with_trainingset2"


all_estimated_parameters=Array[]
all_initial_condition=Array[]

for t = 1:14
    p=zeros(6)

    tstart=tgrid_opt[t]
    tend=tgrid_opt[t+1]
    u0=[trainingset[:,t][1];trainingset[:,t][3:end]]
    push!(all_initial_condition, [u0;tstart])

    prob = ODEProblem(ode_system!, u0, (tstart,tend), p)
    function loss_func()
      sol = solve(prob, AutoTsit5(Rosenbrock23()), p=p, save_everystep=false, save_start=false)#, maxiters=1e7)
      l=Flux.Losses.mse(sol[1,1],trainingset[:,t+1][1])+
      Flux.Losses.mse(sol[2,1],trainingset[:,t+1][3])+
      Flux.Losses.mse(sol[3,1],trainingset[:,t+1][4])+
      Flux.Losses.mse(sol[4,1],trainingset[:,t+1][5])+
      Flux.Losses.mse(sol[5,1],trainingset[:,t+1][6])+
      Flux.Losses.mse(sol[6,1],trainingset[:,t+1][7])
      return l
    end

    epochs = 600
    learning_rate = 0.05
    data = Iterators.repeated((), epochs)
    opt = Adam(learning_rate)
    counter=0

    callback_func = function ()
      global counter=counter+1
      # println("loss: ", loss_func(), "    epoch: ",counter)
    end

    fparams = Flux.params(p)
    Flux.train!(loss_func, fparams, data, opt, cb=callback_func)

    # p = round.(p;digits=4)
    push!(all_estimated_parameters, p)
    println("\n\nParameters estimated: ", p)
    println("loss: ", loss_func(), "    epoch: ",counter, "    t=", t)

    prob = ODEProblem(ode_system!, u0, (tstart,tend), p)
    sol = solve(prob, AutoTsit5(Rosenbrock23()), p=p, saveat = tgrid)

    plots=plot(sol.t,sol', title="from t"*string(t)*" to t"*string(t+1), idxs = (1,2,3,4,5,6), color=[:blue :yellow :orange :green :lightgreen :purple ], label = ["Prediction" "Prediction" "Prediction" "Prediction" "Prediction" "Prediction"], ylabel=["[Xv]"  "[GLC]" "[GLN]" "[LAC]" "[AMM]" "[mAb]"], layout=(3,2),size = (800, 600))
    Plots.scatter!([tgrid_opt[t]],[trainingset[:,t][1];trainingset[:,t][3:end]]' , color=:red,   labels = false, layout=(3,2))#,size = (600, 1000)),title = ["p 1" "p 2" "p 3" "p 4" "p 5" "p 6"],
    Plots.scatter!([tgrid_opt[t+1]],[trainingset[:,t+1][1];trainingset[:,t+1][3:end]]' , color=:red,   labels = "Observed values", layout=(3,2))#,size = (600, 1000)),title = ["p 1" "p 2" "p 3" "p 4" "p 5" "p 6"],
    display(plots)
    savefig(full_path*"/from t"*string(t)*" to t"*string(t+1))

end





println("\n\n all_estimated_parameters ")
# all_estimated_parameters = hcat(all_estimated_parameters...)'
display(all_estimated_parameters)
println("\n\n all_initial_condition")
# all_initial_condition = hcat(all_initial_condition...)'
display(all_initial_condition)

#
#  all_estimated_parameters
# 14-element Vector{Array}:
#  [-0.015830859528148965, -3.378503477914337e-9, 7.224763467398744e-10, -1.0740936771082763e-9, 2.1648308320803066e-10, 1.2732423754124306e-7]
#  [0.12448624082026173, 1.924832295310359e-9, -5.002148982186545e-10, 2.919785009052464e-9, 5.700766259488979e-10, 5.77770489093101e-9]
#  [0.04278860920900389, 1.2338280858001257e-9, 5.165203085799966e-10, -3.9619899486529623e-10, 1.9723838577844013e-10, -1.3322230802048854e-8]
#  [0.06160742078001887, 8.654479278389047e-10, 2.2912216515810558e-10, 2.497219601212557e-10, 1.6253017837552226e-10, 1.021502482703523e-8]
#  [-0.0339344081937107, -5.2138967341248636e-11, 7.944433648118608e-11, 7.224804418890059e-10, 1.6619818472438728e-10, 2.0107338669108602e-8]
#  [0.055634519246425665, 9.853352300165695e-10, 1.9621605491124432e-10, 8.673692872077171e-10, 6.135337454019522e-11, 1.1057126591872423e-8]
#  [0.015629058379224285, 1.3869018897885461e-10, 1.6733504678332108e-10, 5.392269095813433e-10, -2.2397913207819912e-10, 1.7297876465551735e-8]
#  [0.003388311611684094, 2.1012202822841622e-11, 1.0917684681213893e-10, 2.614756917142211e-10, 2.721100336343611e-10, 1.3967736905367779e-8]
#  [0.02851760225408355, 2.816668034437269e-10, 9.054875753236507e-11, 4.4687217576176246e-10, 1.999415608930785e-10, 7.839433581019417e-9]
#  [0.004950424910094593, 6.874997209634604e-10, -2.0447276440002576e-11, 7.079313838038318e-10, -5.653993618160343e-11, 6.191067571447668e-9]
#  [0.0015586934628475217, -1.0561103433632047e-10, 2.1967292452660847e-10, 5.728281241958607e-10, -3.189389323353615e-12, 1.9355455205967542e-8]
#  [-0.005019928013070308, 4.4573663759269985e-11, 2.641828990310612e-12, -2.247159083472563e-10, 3.550830380815356e-12, 1.2486984841459862e-8]
#  [-0.014354479284522171, 6.763098574689804e-10, 1.2879110985045456e-11, 5.453480918413479e-10, -3.972389184408954e-11, 2.913495153215625e-8]
#  [-0.02116900444722298, 5.539901250075835e-11, -7.743047803706361e-11, 4.5879556432771066e-10, 1.038221343301407e-10, 1.384784117232743e-8]
#
#
#  all_initial_condition
# 14-element Vector{Array}:
#  [1.767106549104878e8, 28.79936374789464, 8.67313487957298, 2.942788370043843, 0.39937762872941024, 52.172325660037004, 0.0]
#  [1.581743111876225e8, 32.75525128794138, 7.827187880277974, 1.6851328540289636, 0.6528574257375422, 201.25619728296184, 7.0]
#  [3.780782920512088e8, 29.35504815727434, 8.710815405721698, 6.842912252447374, 1.6598951524771344, 211.46247003201654, 14.0]
#  [5.101075371098536e8, 25.54793104220216, 7.117035112115489, 5.620397407940267, 2.2684938286417715, 170.355176208597, 21.0]
#  [7.85148993232183e8, 21.68421210719685, 6.0941422029583325, 6.735256471998822, 2.994092081099956, 215.95934153698425, 28.0]
#  [6.191407593950603e8, 21.93927189020505, 5.705503661797384, 10.26964865478049, 3.8071332829211215, 314.32509365079693, 35.0]
#  [9.139485475075808e8, 16.71796903965358, 4.665749995434605, 14.865848976492037, 4.132248465169267, 372.91690412697506, 42.0]
#  [1.0196122477857962e9, 15.780324595437056, 3.534445664864008, 18.51141036419648, 2.617989288192452, 489.86301637135585, 49.0]
#  [1.0440846693410515e9, 15.628553643875714, 2.745896700760228, 20.399953060266444, 4.58333958883263, 590.7464098386414, 56.0]
#  [1.2747674922238803e9, 13.350122992624048, 2.0134463160828924, 24.014752782883562, 6.200683466923683, 654.1606596731951, 63.0]
#  [1.3197162842362485e9, 7.107776134642888, 2.199100640685581, 30.44261473909391, 5.6873155651330825, 710.3742173117361, 70.0]
#  [1.3341943566904027e9, 8.088768250313475, 0.1586338112249217, 35.76339722410659, 5.657676638989609, 890.1592175866458, 77.0]
#  [1.288125596141017e9, 7.679720226681464, 0.13440159577627697, 33.701152200604504, 5.690250919760564, 1004.754457067872, 84.0]
#  [1.1649833330008502e9, 1.8778783341683682, 0.023909555859245486, 38.37951703172009, 5.349466508869145, 1254.693440566674, 91.0]
# julia>
