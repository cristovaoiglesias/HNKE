# using DifferentialEquations, DiffEqFlux, Plots, Statistics
# using XLSX, DataFrames, Optim, BlackBoxOptim,DiffEqParamEstim, CSV, Tables
# using Flux
# using BSON: @save
# using BSON#: @load
# using OrdinaryDiffEq, Optimization, OptimizationOptimJL, OptimizationOptimisers
# using Random, ComponentArrays, Lux

# using ComponentArrays, Lux, DiffEqFlux, OrdinaryDiffEq, Optimization, OptimizationOptimJL
# using OptimizationOptimisers, Random, Plots, DifferentialEquations

using Flux, DiffEqFlux, DifferentialEquations, Plots

function ode_system!(du, u, p, t)
    Xv, GLC, GLN, LAC, AMM, mAb = u
    μ_Xv, μ_GLC, μ_GLN, μ_LAC, μ_AMM, μ_mAb = p
    du[1] = μ_Xv*Xv  #dXv
    du[2] = -μ_GLC*Xv #dGLC
    du[3] = -μ_GLN*Xv #dGLN
    du[4] = μ_LAC*Xv #+ klac1*GLC + klac2*GLN   #dLAC
    du[5] = μ_AMM*Xv  #- klac1*GLC  #μ_AMM*Xv - kdeg*du[3] #dAMM #(eq10: dAMM)
    du[6] = μ_mAb*Xv
end
tstart=0.0
tend=103.0
sampling= 7.0
tgrid=tstart:sampling:tend
tgrid_opt=[0.0, 7.0, 14.0, 21.0, 28.0, 35.0, 42.0, 49.0, 56.0, 63.0, 70.0, 77.0, 84.0, 91.0, 98.0]


sol_SP3_trainingset2=[1.3276860336592644e8 3.84839960785678e7 44.596662061215405 10.030872476019958 1.3137307238119043 0.002675178467605843 82.46360766693596; 4.6347200078381467e8 3.58319921448495e8 45.07651625211953 9.775663515082593 0.8742008630745035 1.4523680173438034 93.78496323960847; 6.294480611820064e8 4.4675892507586193e8 44.37947670049955 7.699631921286065 2.6411381417949347 1.9417794308303744 304.737734921819; 3.834587365554175e8 6.241033034482003e8 40.667808939120604 8.24505287075687 3.7673248796265035 2.996821155618602 111.9181021998716; 5.3049792956781745e8 7.068312623040665e8 45.26792398928625 5.803658580406483 4.99198267994125 4.673535667354476 296.3875780775935; 8.332428531350406e8 7.426112574187791e8 42.05902760741853 5.280246446409346 10.006295268582093 2.7346846083189744 370.2164929573426; 9.624919663671308e8 1.2688107281529977e9 36.93519122333163 5.294076113241588 22.205187754304664 3.4056363710776676 493.43600858797816; 9.05530737969483e8 1.2702099125728152e9 33.04572414416723 3.5729381155999325 21.631708893516763 4.611224383546274 401.26437910900734; 1.1950403674931133e9 1.093401214082508e9 35.92258021542968 2.6306642955101154 24.989180585626464 5.947295390108509 731.1002893971281; 1.1778862157184963e9 1.5615287348126175e9 28.43956935116414 3.9206605920006714 23.736473834417332 5.774472266730323 745.8656463160272; 1.301655071960574e9 1.5950995958985288e9 28.81663882456461 2.3484099184574108 30.266721219976354 4.976589748516753 813.6090462077134; 1.2337522937577212e9 2.11605475973432e9 18.061513364200906 1.2055650517897694 34.367769533017956 6.018080892625003 998.114095738896; 1.7764097885406265e9 2.18857808048989e9 14.614713505091318 0.32939850299444967 39.56432966624392 5.643319636871412 1042.2690182253198; 1.4893954895751016e9 1.730104377624241e9 19.6825807847662 0.20975168920556794 42.74304071666453 6.70570760561382 1251.9202608145938; 1.196784477248542e9 1.5070615016873164e9 17.731156275034824 1.2793724084082994 38.505678777465704 7.520375228639099 1366.4151108358883]'

trainingset=sol_SP3_trainingset2

full_path="/Users/cristovao/PhD_courses/Thesis/BHM_NSE_vs_EnMLP_NSE/estimating_parameters/SP3/estimation_with_trainingset2"


all_estimated_parameters=Array[]
all_initial_condition=Array[]

for t = 1:14
    p=zeros(6)

    tstart=tgrid_opt[t]
    tend=tgrid_opt[t+1]
    u0=[trainingset[:,t][1];trainingset[:,t][3:end]]
    push!(all_initial_condition, [u0;tstart])

    prob = ODEProblem(ode_system!, u0, (tstart,tend), p)
    function loss_func()
      sol = solve(prob, AutoTsit5(Rosenbrock23()), p=p, save_everystep=false, save_start=false)#, maxiters=1e7)
      l=Flux.Losses.mse(sol[1,1],trainingset[:,t+1][1])+
      Flux.Losses.mse(sol[2,1],trainingset[:,t+1][3])+
      Flux.Losses.mse(sol[3,1],trainingset[:,t+1][4])+
      Flux.Losses.mse(sol[4,1],trainingset[:,t+1][5])+
      Flux.Losses.mse(sol[5,1],trainingset[:,t+1][6])+
      Flux.Losses.mse(sol[6,1],trainingset[:,t+1][7])
      return l
    end

    epochs = 600
    learning_rate = 0.05
    data = Iterators.repeated((), epochs)
    opt = Adam(learning_rate)
    counter=0

    callback_func = function ()
      global counter=counter+1
      # println("loss: ", loss_func(), "    epoch: ",counter)
    end

    fparams = Flux.params(p)
    Flux.train!(loss_func, fparams, data, opt, cb=callback_func)

    # p = round.(p;digits=4)
    push!(all_estimated_parameters, p)
    println("\n\nParameters estimated: ", p)
    println("loss: ", loss_func(), "    epoch: ",counter, "    t=", t)

    prob = ODEProblem(ode_system!, u0, (tstart,tend), p)
    sol = solve(prob, AutoTsit5(Rosenbrock23()), p=p, saveat = tgrid)

    plots=plot(sol.t,sol', title="from t"*string(t)*" to t"*string(t+1), idxs = (1,2,3,4,5,6), color=[:blue :yellow :orange :green :lightgreen :purple ], label = ["Prediction" "Prediction" "Prediction" "Prediction" "Prediction" "Prediction"], ylabel=["[Xv]"  "[GLC]" "[GLN]" "[LAC]" "[AMM]" "[mAb]"], layout=(3,2),size = (800, 600))
    Plots.scatter!([tgrid_opt[t]],[trainingset[:,t][1];trainingset[:,t][3:end]]' , color=:red,   labels = false, layout=(3,2))#,size = (600, 1000)),title = ["p 1" "p 2" "p 3" "p 4" "p 5" "p 6"],
    Plots.scatter!([tgrid_opt[t+1]],[trainingset[:,t+1][1];trainingset[:,t+1][3:end]]' , color=:red,   labels = "Observed values", layout=(3,2))#,size = (600, 1000)),title = ["p 1" "p 2" "p 3" "p 4" "p 5" "p 6"],
    display(plots)
    savefig(full_path*"/from t"*string(t)*" to t"*string(t+1))

end





println("\n\n all_estimated_parameters ")
# all_estimated_parameters = hcat(all_estimated_parameters...)'
display(all_estimated_parameters)
println("\n\n all_initial_condition")
# all_initial_condition = hcat(all_initial_condition...)'
display(all_initial_condition)

# # #
# all_estimated_parameters
# 14-element Vector{Array}:
# [0.17859117999895957, -2.59138278660647e-10, 1.3782214760828177e-10, -2.3736175696985826e-10, 7.828844206750982e-10, 6.113920962582905e-9]
# [0.04372819527017241, 1.8364243543441384e-10, 5.469528619567969e-10, 4.65518608522893e-10, 1.2894054802958494e-10, 5.557779800907537e-8]
# [-0.0708016223817904, 1.0683070172496881e-9, -1.5698531059572207e-10, 3.2414362163598114e-10, 3.036663820023776e-10, -5.549811101154539e-8]
# [0.04636914817076007, -1.4506568281738859e-9, 7.698992646878632e-10, 3.86198610216885e-10, 5.287557353222581e-10, 5.817287403297554e-8]
# [0.0645012982182303, 6.836714696375149e-10, 1.1151581367212496e-10, 1.0683242915246154e-9, -4.1308205345789984e-10, 1.5729614502065083e-8]
# [0.02060008277320118, 8.166514303165795e-10, -2.2043620623866174e-12, 1.9442935291525786e-9, 1.0693830746116637e-10, 1.9639068906024487e-8]
# [-0.008714928127995973, 5.950786564444012e-10, 2.633296293385993e-10, -8.774059843700737e-11, 1.8445174707293365e-10, -1.4102032806763824e-8]
# [0.03963057448137026, -3.9380768473474627e-10, 1.289853846199418e-10, 4.595984951832186e-10, 1.8289173915056582e-10, 4.515078233835134e-8]
# [-0.0020654965212297074, 9.010136869529915e-10, -1.553254003222042e-10, -1.5083544202712125e-10, -2.0808851037330056e-11, 1.7778661620607677e-9]
# [0.014273585357586068, -4.348439333662392e-11, 1.8131810527417975e-10, 7.53096753155924e-10, -9.201446056944645e-11, 7.812474886204806e-9]
# [-0.007653773722860122, 1.212282128344682e-9, 1.288180555438381e-10, 4.6225683970540624e-10, 1.1739380341477087e-10, 2.0796791605322163e-8]
# [0.05207631218027404, 3.3077436318244777e-10, 8.408265790267337e-11, 4.986907066456083e-10, -3.596512737800781e-11, 4.237343281190685e-9]
# [-0.02517486129575879, -4.4451625708151264e-10, 1.0493407565789867e-11, 2.7881285411995944e-10, 9.318398395574267e-11, 1.838912081291708e-8]
# [-0.031247424113834556, 2.0839070036660384e-10, -1.1422439811851852e-10, -4.5250200632322054e-10, 8.699839776379363e-11, 1.2226708535452407e-8]
#
#
# all_initial_condition
# 14-element Vector{Array}:
# [1.3276860336592644e8, 44.596662061215405, 10.030872476019958, 1.3137307238119043, 0.002675178467605843, 82.46360766693596, 0.0]
# [4.6347200078381467e8, 45.07651625211953, 9.775663515082593, 0.8742008630745035, 1.4523680173438034, 93.78496323960847, 7.0]
# [6.294480611820064e8, 44.37947670049955, 7.699631921286065, 2.6411381417949347, 1.9417794308303744, 304.737734921819, 14.0]
# [3.834587365554175e8, 40.667808939120604, 8.24505287075687, 3.7673248796265035, 2.996821155618602, 111.9181021998716, 21.0]
# [5.3049792956781745e8, 45.26792398928625, 5.803658580406483, 4.99198267994125, 4.673535667354476, 296.3875780775935, 28.0]
# [8.332428531350406e8, 42.05902760741853, 5.280246446409346, 10.006295268582093, 2.7346846083189744, 370.2164929573426, 35.0]
# [9.624919663671308e8, 36.93519122333163, 5.294076113241588, 22.205187754304664, 3.4056363710776676, 493.43600858797816, 42.0]
# [9.05530737969483e8, 33.04572414416723, 3.5729381155999325, 21.631708893516763, 4.611224383546274, 401.26437910900734, 49.0]
# [1.1950403674931133e9, 35.92258021542968, 2.6306642955101154, 24.989180585626464, 5.947295390108509, 731.1002893971281, 56.0]
# [1.1778862157184963e9, 28.43956935116414, 3.9206605920006714, 23.736473834417332, 5.774472266730323, 745.8656463160272, 63.0]
# [1.301655071960574e9, 28.81663882456461, 2.3484099184574108, 30.266721219976354, 4.976589748516753, 813.6090462077134, 70.0]
# [1.2337522937577212e9, 18.061513364200906, 1.2055650517897694, 34.367769533017956, 6.018080892625003, 998.114095738896, 77.0]
# [1.7764097885406265e9, 14.614713505091318, 0.32939850299444967, 39.56432966624392, 5.643319636871412, 1042.2690182253198, 84.0]
# [1.4893954895751016e9, 19.6825807847662, 0.20975168920556794, 42.74304071666453, 6.70570760561382, 1251.9202608145938, 91.0]
# julia>
